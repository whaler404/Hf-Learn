通常情况下，🤗 PEFT 中无法混合使用不同类型的适配器。可以创建一个包含两个不同 LoRA 适配器（它们可以具有不同的配置选项）的 PEFT 模型，但无法组合使用 LoRA 和 LoHa 适配器。

使用 PeftMixedModel 时，只要适配器类型兼容，就可以实现混合适配器。允许混合适配器类型的主要目的是将已训练的适配器组合起来进行推理

